{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fossil-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "wired-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodings with -1 and without one hot encoding\n",
    "train_1 = pd.read_csv(\"train_1encoded.csv\")\n",
    "train_1['SettlementProcess'].replace({'Card':0, 'Bank':1, 'Check':2, 'Electronic':3}, inplace=True)\n",
    "test_1  = pd.read_csv(\"test_1encoded.csv\")\n",
    "test_1['SettlementProcess'].replace({'Card':0, 'Bank':1, 'Check':2, 'Electronic':3}, inplace=True)\n",
    "\n",
    "# Encodings without -1 and with one hot encoding\n",
    "train_2 = pd.read_csv(\"train_encoded_noh.csv\")\n",
    "train_2['SettlementProcess'].replace({'Card':0, 'Bank':1, 'Check':2, 'Electronic':3}, inplace=True)\n",
    "test_2  = pd.read_csv(\"test_encoded_noh.csv\")\n",
    "test_2['SettlementProcess'].replace({'Card':0, 'Bank':1, 'Check':2, 'Electronic':3}, inplace=True)\n",
    "\n",
    "# Trivial encoding based on prev without 1 and one hot encoding is done\n",
    "train_3 = pd.read_csv(\"train_encoded.csv\")\n",
    "test_3  = pd.read_csv(\"test_encoded.csv\")\n",
    "\n",
    "# Introduce few new features train_1  ----->\n",
    "\n",
    "train_4 = train_1.copy()\n",
    "train_4['G/Q'] = train_4['GrandPayment']/train_4['QuarterlyPayment']\n",
    "train_4['G/S'] = train_4['GrandPayment']/(train_4['ServiceSpan']+1)\n",
    "train_4['Q/S'] = train_4['QuarterlyPayment']/(train_4['ServiceSpan']+1)\n",
    "train_4['Services_add'] = train_4['MobileService']+train_4['4GService']+ train_4['CyberProtection']+ train_4['HardwareSupport']+train_4['TechnicalAssistance'] + train_4['FilmSubscription']\n",
    "train_4['SAMT'] = train_4['sex']*(1-train_4['Aged'])*(1-train_4['Married']) +train_4['TotalDependents']\n",
    "\n",
    "test_4 = test_1.copy()\n",
    "test_4['G/Q'] = test_4['GrandPayment']/test_4['QuarterlyPayment']\n",
    "test_4['G/S'] = test_4['GrandPayment']/(test_4['ServiceSpan'] +1)\n",
    "test_4['Q/S'] = test_4['QuarterlyPayment']/(test_4['ServiceSpan']+1)\n",
    "test_4['Services_add'] = test_4['MobileService']+test_4['4GService']+ test_4['CyberProtection']+ test_4['HardwareSupport']+test_4['TechnicalAssistance'] + test_4['FilmSubscription']\n",
    "test_4['SAMT'] = test_4['sex']*(1-test_4['Aged'])*(1-test_4['Married']) +test_4['TotalDependents']\n",
    "\n",
    "# Introduce few new features train_2  ----->\n",
    "\n",
    "train_5 = train_2.copy()\n",
    "train_5['G/Q'] = train_5['GrandPayment']/train_5['QuarterlyPayment']\n",
    "train_5['G/S'] = train_5['GrandPayment']/(train_5['ServiceSpan'] +1)\n",
    "train_5['Q/S'] = train_5['QuarterlyPayment']/(train_5['ServiceSpan']+1)\n",
    "train_5['Services_add']= train_5['MobileService']+train_5['4GService']+ train_5['CyberProtection']+ train_5['HardwareSupport']+train_5['TechnicalAssistance'] + train_5['FilmSubscription']\n",
    "train_5['SAMT'] = train_5['sex']*(1-train_5['Aged'])*(1-train_5['Married']) +train_5['TotalDependents']\n",
    "\n",
    "test_5 = test_2.copy()\n",
    "test_5['G/Q'] = test_5['GrandPayment']/test_5['QuarterlyPayment']\n",
    "test_5['G/S'] = test_5['GrandPayment']/(test_5['ServiceSpan']+1)\n",
    "test_5['Q/S'] = test_5['QuarterlyPayment']/(test_5['ServiceSpan'] +1)\n",
    "test_5['Services_add'] = test_5['MobileService']+test_5['4GService']+ test_5['CyberProtection']+ test_5['HardwareSupport']+test_5['TechnicalAssistance'] + test_5['FilmSubscription']\n",
    "test_5['SAMT'] = test_5['sex']*(1-test_5['Aged'])*(1-test_5['Married']) +test_5['TotalDependents']\n",
    "\n",
    "# Introduce few new features train_3  ----->\n",
    "\n",
    "train_6 = train_3.copy()\n",
    "train_6['G/Q'] = train_6['GrandPayment']/train_6['QuarterlyPayment']\n",
    "train_6['G/S'] = train_6['GrandPayment']/(train_6['ServiceSpan']+1)\n",
    "train_6['Q/S'] = train_6['QuarterlyPayment']/(train_6['ServiceSpan']+1)\n",
    "train_6['Services_add'] = train_6['MobileService']+train_6['4GService']+ train_6['CyberProtection']+ train_6['HardwareSupport']+train_6['TechnicalAssistance'] + train_6['FilmSubscription']\n",
    "train_6['SAMT'] = train_6['sex']*(1-train_6['Aged'])*(1-train_6['Married']) +train_6['TotalDependents']\n",
    "\n",
    "test_6 = test_3.copy()\n",
    "test_6['G/Q'] = test_6['GrandPayment']/test_6['QuarterlyPayment']\n",
    "test_6['G/S'] = test_6['GrandPayment']/(test_6['ServiceSpan']+1)\n",
    "test_6['Q/S'] = test_6['QuarterlyPayment']/(test_6['ServiceSpan']+1)\n",
    "test_6['Services_add'] = test_6['MobileService']+test_6['4GService']+ test_6['CyberProtection']+ test_6['HardwareSupport']+test_6['TechnicalAssistance'] + test_6['FilmSubscription']\n",
    "test_6['SAMT'] = test_6['sex']*(1-test_6['Aged'])*(1-test_6['Married']) +test_6['TotalDependents']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "backed-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "### General ###\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"./tfms\")\n",
    "\n",
    "### Data Wrangling ###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from gauss_rank_scaler import GaussRankScaler\n",
    "\n",
    "### Data Visualization ###\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "### Machine Learning ###\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "### Make prettier the prints ###\n",
    "from colorama import Fore\n",
    "c_ = Fore.CYAN\n",
    "m_ = Fore.MAGENTA\n",
    "r_ = Fore.RED\n",
    "b_ = Fore.BLUE\n",
    "y_ = Fore.YELLOW\n",
    "g_ = Fore.GREEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "commercial-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "accessible-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "express-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "thermal-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = \"rankgauss\"   # boxcox , norm ,minmax , rankgauss\n",
    "variance_threshould = None\n",
    "decompo = \"no\" #\"PCA\"\n",
    "ncompo = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "casual-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(df,dum_cols,val = 0):\n",
    "    if val == 0:\n",
    "        return df\n",
    "    return pd.get_dummies(df, prefix=None, prefix_sep='_', dummy_na=False, columns=dum_cols)\n",
    "\n",
    "def normalize(df):\n",
    "    return (df - df.mean(0) )/df.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "successful-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_6.copy()\n",
    "test_df  = test_6.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "stunning-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_df.drop(['CustomerAttrition','ID'],axis=1)\n",
    "train_targets_scored = train_df['CustomerAttrition']\n",
    "\n",
    "test_features = test_df.drop(['ID'],axis=1)\n",
    "sample_submission = pd.read_csv('Sample Submission.csv')\n",
    "\n",
    "concat = pd.concat([train_features,test_features],axis=0)\n",
    "\n",
    "create_dummy = 0                #0 if dont want dummies\n",
    "dum_cols = ['age', 'experience', 'married', 'house_ownership',\n",
    "       'car_ownership', 'profession', 'city', 'state', 'current_job_years',\n",
    "       'current_house_years']\n",
    "\n",
    "concat = get_dummies(concat,dum_cols,create_dummy)\n",
    "# norm_concat = normalize(concat)\n",
    "\n",
    "train_features = concat[:len(train_features)]\n",
    "test_features  = concat[len(train_features):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "sapphire-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = concat.copy()\n",
    "cols_numeric = [feat for feat in list(data_all.columns)]\n",
    "if variance_threshould:\n",
    "    mask = (data_all[cols_numeric].var() >= variance_threshould).values\n",
    "    data_all = data_all[cols_numeric].loc[:, mask]\n",
    "    cols_numeric = [feat for feat in list(data_all.columns)]\n",
    "data_all.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "vulnerable-thirty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.isin([np.inf, -np.inf]).values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "better-theme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m Rank Gauss\n"
     ]
    }
   ],
   "source": [
    "def scale_minmax(col):\n",
    "    return (col - col.min()) / (col.max() - col.min())\n",
    "\n",
    "def scale_norm(col):\n",
    "    return (col - col.mean()) / col.std()\n",
    "\n",
    "if scale == \"boxcox\":\n",
    "    print(b_, \"boxcox\")\n",
    "    data_all[cols_numeric] = data_all[cols_numeric].apply(scale_minmax, axis = 0)\n",
    "    trans = []\n",
    "    for feat in cols_numeric:\n",
    "        trans_var, lambda_var = stats.boxcox(data_all[feat].dropna() + 1)\n",
    "        trans.append(scale_minmax(trans_var))\n",
    "    data_all[cols_numeric] = np.asarray(trans).T\n",
    "    \n",
    "elif scale == \"norm\":\n",
    "    print(b_, \"norm\")\n",
    "    data_all[cols_numeric] = data_all[cols_numeric].apply(scale_norm, axis = 0)\n",
    "    \n",
    "elif scale == \"minmax\":\n",
    "    print(b_, \"minmax\")\n",
    "    data_all[cols_numeric] = data_all[cols_numeric].apply(scale_minmax, axis = 0)\n",
    "    \n",
    "elif scale == \"rankgauss\":\n",
    "    ### Rank Gauss ###\n",
    "    print(b_, \"Rank Gauss\")\n",
    "    scaler = GaussRankScaler()\n",
    "    data_all[cols_numeric] = scaler.fit_transform(data_all[cols_numeric])\n",
    "    \n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "fifth-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "if decompo == \"PCA\":\n",
    "    print(b_, \"PCA\")\n",
    "    \n",
    "    pca_genes = PCA(n_components = ncompo,\n",
    "                    random_state = seed).fit_transform(data_all)\n",
    "    \n",
    "    pca_genes = pd.DataFrame(pca_genes, columns = [f\"pcaHarsh-{i}\" for i in range(ncompo)])\n",
    "    data_all = pd.concat([data_all, pca_genes], axis=1)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "tough-genealogy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mtrain_df.shape: \u001b[31m(6337, 24)\n",
      "\u001b[34mtest_df.shape: \u001b[31m(705, 23)\n",
      "\u001b[34mX_test.shape: \u001b[31m(705, 23)\n"
     ]
    }
   ],
   "source": [
    "train_df = data_all[: train_df.shape[0]]\n",
    "train_df = pd.concat([train_df,train_targets_scored],axis=1)\n",
    "train_df.reset_index(drop = True, inplace = True)\n",
    "test_df = data_all[train_df.shape[0]: ]\n",
    "test_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "print(f\"{b_}train_df.shape: {r_}{train_df.shape}\")\n",
    "print(f\"{b_}test_df.shape: {r_}{test_df.shape}\")\n",
    "\n",
    "X_test = test_df.values\n",
    "print(f\"{b_}X_test.shape: {r_}{X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "familiar-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_eval(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    err = accuracy_score(y_true, np.round(y_pred))\n",
    "    return 'f1_err', err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "corporate-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _F1_eval(preds, labels):\n",
    "    t = np.arange(0, 1, 0.005)\n",
    "    f = np.repeat(0, 200)\n",
    "    results = np.vstack([t, f]).T\n",
    "    # assuming labels only containing 0's and 1's\n",
    "    n_pos_examples = sum(labels)\n",
    "    if n_pos_examples == 0:\n",
    "        raise ValueError(\"labels not containing positive examples\")\n",
    "\n",
    "    for i in range(200):\n",
    "        pred_indexes = (preds >= results[i, 0])\n",
    "        TP = sum(labels[pred_indexes])\n",
    "        FP = len(labels[pred_indexes]) - TP\n",
    "        precision = 0\n",
    "        recall = TP / n_pos_examples\n",
    "\n",
    "        if (FP + TP) > 0:\n",
    "            precision = TP / (FP + TP)\n",
    "\n",
    "        if (precision + recall > 0):\n",
    "            F1 = 2 * precision * recall / (precision + recall)\n",
    "        else:\n",
    "            F1 = 0\n",
    "        results[i, 1] = F1\n",
    "    return (max(results[:, 1]))\n",
    "\n",
    "def F1_eval(preds, dtrain):\n",
    "    res = _F1_eval(preds, dtrain.get_label())\n",
    "    return 'f1_err', 1-res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "polyphonic-whole",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m FOLDS:  \u001b[31m 1\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "[09:07:19] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:07:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67202\tvalidation_0-f1_err:0.52651\n",
      "[1]\tvalidation_0-logloss:0.65375\tvalidation_0-f1_err:0.47935\n",
      "[2]\tvalidation_0-logloss:0.63659\tvalidation_0-f1_err:0.51595\n",
      "[3]\tvalidation_0-logloss:0.62086\tvalidation_0-f1_err:0.47143\n",
      "[4]\tvalidation_0-logloss:0.60671\tvalidation_0-f1_err:0.48188\n",
      "[5]\tvalidation_0-logloss:0.59407\tvalidation_0-f1_err:0.45326\n",
      "[6]\tvalidation_0-logloss:0.58242\tvalidation_0-f1_err:0.49270\n",
      "[7]\tvalidation_0-logloss:0.57173\tvalidation_0-f1_err:0.49450\n",
      "[8]\tvalidation_0-logloss:0.56176\tvalidation_0-f1_err:0.48000\n",
      "[9]\tvalidation_0-logloss:0.55260\tvalidation_0-f1_err:0.49177\n",
      "[10]\tvalidation_0-logloss:0.54432\tvalidation_0-f1_err:0.49265\n",
      "[11]\tvalidation_0-logloss:0.53648\tvalidation_0-f1_err:0.49446\n",
      "[12]\tvalidation_0-logloss:0.52878\tvalidation_0-f1_err:0.49814\n",
      "[13]\tvalidation_0-logloss:0.52228\tvalidation_0-f1_err:0.49630\n",
      "[14]\tvalidation_0-logloss:0.51594\tvalidation_0-f1_err:0.48614\n",
      "[15]\tvalidation_0-logloss:0.51004\tvalidation_0-f1_err:0.49064\n",
      "Train acc: 0.8177155257447228 f1: 0.5986099044309297\n",
      "Val acc: 0.7973186119873817 f1: 0.5467372134038802\n",
      "\u001b[34m FOLDS:  \u001b[31m 2\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "[09:07:19] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:07:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67278\tvalidation_0-f1_err:0.45894\n",
      "[1]\tvalidation_0-logloss:0.65507\tvalidation_0-f1_err:0.46493\n",
      "[2]\tvalidation_0-logloss:0.63887\tvalidation_0-f1_err:0.46141\n",
      "[3]\tvalidation_0-logloss:0.62350\tvalidation_0-f1_err:0.46053\n",
      "[4]\tvalidation_0-logloss:0.60998\tvalidation_0-f1_err:0.45424\n",
      "[5]\tvalidation_0-logloss:0.59748\tvalidation_0-f1_err:0.46367\n",
      "[6]\tvalidation_0-logloss:0.58543\tvalidation_0-f1_err:0.46099\n",
      "[7]\tvalidation_0-logloss:0.57461\tvalidation_0-f1_err:0.46918\n",
      "[8]\tvalidation_0-logloss:0.56530\tvalidation_0-f1_err:0.47703\n",
      "[9]\tvalidation_0-logloss:0.55612\tvalidation_0-f1_err:0.46459\n",
      "[10]\tvalidation_0-logloss:0.54793\tvalidation_0-f1_err:0.46274\n",
      "[11]\tvalidation_0-logloss:0.54050\tvalidation_0-f1_err:0.47295\n",
      "[12]\tvalidation_0-logloss:0.53354\tvalidation_0-f1_err:0.47644\n",
      "[13]\tvalidation_0-logloss:0.52686\tvalidation_0-f1_err:0.47735\n",
      "[14]\tvalidation_0-logloss:0.52104\tvalidation_0-f1_err:0.47552\n",
      "Train acc: 0.8159763313609467 f1: 0.6205774705164702\n",
      "Val acc: 0.7845303867403315 f1: 0.5457570715474209\n",
      "\u001b[34m FOLDS:  \u001b[31m 3\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "[09:07:19] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:07:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67235\tvalidation_0-f1_err:0.44874\n",
      "[1]\tvalidation_0-logloss:0.65363\tvalidation_0-f1_err:0.41987\n",
      "[2]\tvalidation_0-logloss:0.63598\tvalidation_0-f1_err:0.41431\n",
      "[3]\tvalidation_0-logloss:0.62074\tvalidation_0-f1_err:0.42857\n",
      "[4]\tvalidation_0-logloss:0.60610\tvalidation_0-f1_err:0.42517\n",
      "[5]\tvalidation_0-logloss:0.59326\tvalidation_0-f1_err:0.42132\n",
      "[6]\tvalidation_0-logloss:0.58135\tvalidation_0-f1_err:0.42954\n",
      "[7]\tvalidation_0-logloss:0.57090\tvalidation_0-f1_err:0.42475\n",
      "[8]\tvalidation_0-logloss:0.56049\tvalidation_0-f1_err:0.41379\n",
      "[9]\tvalidation_0-logloss:0.55092\tvalidation_0-f1_err:0.40513\n",
      "[10]\tvalidation_0-logloss:0.54236\tvalidation_0-f1_err:0.42466\n",
      "[11]\tvalidation_0-logloss:0.53457\tvalidation_0-f1_err:0.41157\n",
      "[12]\tvalidation_0-logloss:0.52712\tvalidation_0-f1_err:0.42114\n",
      "[13]\tvalidation_0-logloss:0.52010\tvalidation_0-f1_err:0.42708\n",
      "[14]\tvalidation_0-logloss:0.51350\tvalidation_0-f1_err:0.41979\n",
      "[15]\tvalidation_0-logloss:0.50750\tvalidation_0-f1_err:0.41781\n",
      "[16]\tvalidation_0-logloss:0.50236\tvalidation_0-f1_err:0.42808\n",
      "[17]\tvalidation_0-logloss:0.49730\tvalidation_0-f1_err:0.42222\n",
      "[18]\tvalidation_0-logloss:0.49266\tvalidation_0-f1_err:0.42564\n",
      "[19]\tvalidation_0-logloss:0.48823\tvalidation_0-f1_err:0.42760\n",
      "Train acc: 0.8271848490826593 f1: 0.626916524701874\n",
      "Val acc: 0.8091482649842271 f1: 0.5898305084745763\n",
      "\u001b[34m FOLDS:  \u001b[31m 4\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "[09:07:19] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:07:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67267\tvalidation_0-f1_err:0.48122\n",
      "[1]\tvalidation_0-logloss:0.65382\tvalidation_0-f1_err:0.44295\n",
      "[2]\tvalidation_0-logloss:0.63644\tvalidation_0-f1_err:0.47310\n",
      "[3]\tvalidation_0-logloss:0.62080\tvalidation_0-f1_err:0.45290\n",
      "[4]\tvalidation_0-logloss:0.60616\tvalidation_0-f1_err:0.44927\n",
      "[5]\tvalidation_0-logloss:0.59280\tvalidation_0-f1_err:0.44927\n",
      "[6]\tvalidation_0-logloss:0.58113\tvalidation_0-f1_err:0.45255\n",
      "[7]\tvalidation_0-logloss:0.56980\tvalidation_0-f1_err:0.45648\n",
      "[8]\tvalidation_0-logloss:0.56004\tvalidation_0-f1_err:0.44326\n",
      "[9]\tvalidation_0-logloss:0.55007\tvalidation_0-f1_err:0.44186\n",
      "[10]\tvalidation_0-logloss:0.54212\tvalidation_0-f1_err:0.43986\n",
      "[11]\tvalidation_0-logloss:0.53381\tvalidation_0-f1_err:0.44028\n",
      "[12]\tvalidation_0-logloss:0.52670\tvalidation_0-f1_err:0.44028\n",
      "[13]\tvalidation_0-logloss:0.51950\tvalidation_0-f1_err:0.44043\n",
      "[14]\tvalidation_0-logloss:0.51358\tvalidation_0-f1_err:0.44043\n",
      "[15]\tvalidation_0-logloss:0.50702\tvalidation_0-f1_err:0.43672\n",
      "[16]\tvalidation_0-logloss:0.50156\tvalidation_0-f1_err:0.43816\n",
      "[17]\tvalidation_0-logloss:0.49603\tvalidation_0-f1_err:0.43563\n",
      "[18]\tvalidation_0-logloss:0.49083\tvalidation_0-f1_err:0.42958\n",
      "[19]\tvalidation_0-logloss:0.48610\tvalidation_0-f1_err:0.43162\n",
      "[20]\tvalidation_0-logloss:0.48208\tvalidation_0-f1_err:0.42908\n",
      "[21]\tvalidation_0-logloss:0.47833\tvalidation_0-f1_err:0.43210\n",
      "[22]\tvalidation_0-logloss:0.47451\tvalidation_0-f1_err:0.44071\n",
      "[23]\tvalidation_0-logloss:0.47129\tvalidation_0-f1_err:0.43816\n",
      "[24]\tvalidation_0-logloss:0.46746\tvalidation_0-f1_err:0.43009\n",
      "[25]\tvalidation_0-logloss:0.46458\tvalidation_0-f1_err:0.42958\n",
      "[26]\tvalidation_0-logloss:0.46197\tvalidation_0-f1_err:0.43761\n",
      "[27]\tvalidation_0-logloss:0.45951\tvalidation_0-f1_err:0.43652\n",
      "[28]\tvalidation_0-logloss:0.45691\tvalidation_0-f1_err:0.43154\n",
      "[29]\tvalidation_0-logloss:0.45521\tvalidation_0-f1_err:0.43206\n",
      "[30]\tvalidation_0-logloss:0.45295\tvalidation_0-f1_err:0.43106\n",
      "Train acc: 0.8266272189349112 f1: 0.6101995565410199\n",
      "Val acc: 0.8089976322020521 f1: 0.5709219858156029\n",
      "\u001b[34m FOLDS:  \u001b[31m 5\n",
      "\u001b[32m ************************************************************ \u001b[36m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:07:19] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:07:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67299\tvalidation_0-f1_err:0.55235\n",
      "[1]\tvalidation_0-logloss:0.65500\tvalidation_0-f1_err:0.57088\n",
      "[2]\tvalidation_0-logloss:0.63856\tvalidation_0-f1_err:0.53047\n",
      "[3]\tvalidation_0-logloss:0.62316\tvalidation_0-f1_err:0.51986\n",
      "[4]\tvalidation_0-logloss:0.60966\tvalidation_0-f1_err:0.52813\n",
      "[5]\tvalidation_0-logloss:0.59736\tvalidation_0-f1_err:0.52747\n",
      "[6]\tvalidation_0-logloss:0.58580\tvalidation_0-f1_err:0.49733\n",
      "[7]\tvalidation_0-logloss:0.57484\tvalidation_0-f1_err:0.48330\n",
      "[8]\tvalidation_0-logloss:0.56528\tvalidation_0-f1_err:0.49553\n",
      "[9]\tvalidation_0-logloss:0.55566\tvalidation_0-f1_err:0.48511\n",
      "[10]\tvalidation_0-logloss:0.54738\tvalidation_0-f1_err:0.48754\n",
      "[11]\tvalidation_0-logloss:0.54015\tvalidation_0-f1_err:0.48330\n",
      "[12]\tvalidation_0-logloss:0.53344\tvalidation_0-f1_err:0.48070\n",
      "[13]\tvalidation_0-logloss:0.52678\tvalidation_0-f1_err:0.48772\n",
      "[14]\tvalidation_0-logloss:0.52114\tvalidation_0-f1_err:0.49027\n",
      "[15]\tvalidation_0-logloss:0.51584\tvalidation_0-f1_err:0.49643\n",
      "[16]\tvalidation_0-logloss:0.51062\tvalidation_0-f1_err:0.49736\n",
      "[17]\tvalidation_0-logloss:0.50596\tvalidation_0-f1_err:0.49650\n",
      "[18]\tvalidation_0-logloss:0.50157\tvalidation_0-f1_err:0.49912\n",
      "[19]\tvalidation_0-logloss:0.49750\tvalidation_0-f1_err:0.49047\n",
      "[20]\tvalidation_0-logloss:0.49364\tvalidation_0-f1_err:0.49135\n",
      "[21]\tvalidation_0-logloss:0.49040\tvalidation_0-f1_err:0.49301\n",
      "Train acc: 0.8287968441814596 f1: 0.617283950617284\n",
      "Val acc: 0.7837411207576953 f1: 0.519298245614035\n"
     ]
    }
   ],
   "source": [
    "scores_auc_all = []\n",
    "test_cv_preds = []\n",
    "\n",
    "NB_SPLITS = 5\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, random_state = 0, shuffle = True)\n",
    "\n",
    "oof_preds = []\n",
    "oof_targets = []\n",
    "scores = []\n",
    "scores_auc = []\n",
    "\n",
    "# for mskf\n",
    "ms_tar = np.array(train_df)\n",
    "targets = train_df.CustomerAttrition.values\n",
    "train_it = train_df.drop(['CustomerAttrition'],axis=1)\n",
    "#####\n",
    "\n",
    "for fold_nb, (train_idx, val_idx) in enumerate(mskf.split(train_it, ms_tar)):\n",
    "    print(b_,\"FOLDS: \", r_, fold_nb + 1)\n",
    "    print(g_, '*' * 60, c_)\n",
    "    \n",
    "    X_train, y_train = train_it.values[train_idx, :], np.array(targets).reshape(-1,1)[train_idx]\n",
    "    X_val, y_val = train_it.values[val_idx, :], np.array(targets).reshape(-1,1)[val_idx]\n",
    "    ### Model ###\n",
    "    \n",
    "    \n",
    "#     model = DecisionTreeClassifier(max_depth = 4,random_state=42)\n",
    "#     model = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,max_features='log2',subsample=0.9,random_state=42)\n",
    "    \n",
    "    model = xgb.XGBClassifier(max_depth=6, learning_rate=0.05,silent=False, objective='binary:logistic',\n",
    "                      booster='gbtree', n_jobs=8, nthread=4, gamma=0, min_child_weight=1, max_delta_step=0,\n",
    "                      subsample=0.8, colsample_bytree=0.8, colsample_bylevel=1, reg_alpha=0, reg_lambda=1)\n",
    "    \n",
    "    \n",
    "    model.fit(X_train,y_train, early_stopping_rounds=10, eval_set=[(X_val, y_val)],eval_metric = F1_eval)\n",
    "    \n",
    "    y_pred = model.predict(X_train)\n",
    "    acc = accuracy_score(y_train, y_pred)\n",
    "    f1  = f1_score(y_train,y_pred)\n",
    "    print(f'Train acc: {acc} f1: {f1}')\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    f1  = f1_score(y_val,y_pred)\n",
    "    print(f'Val acc: {acc} f1: {f1}')\n",
    "    \n",
    "    \n",
    "    ### Save OOF for CV ###\n",
    "    oof_preds.append(y_pred)\n",
    "    oof_targets.append(y_val.reshape(-1,))\n",
    "    scores.append(f1)\n",
    "    \n",
    "    ### Predict on test ###\n",
    "    preds_test = model.predict_proba(X_test)[:,1:].reshape(-1)\n",
    "    test_cv_preds.append(preds_test)\n",
    "\n",
    "oof_preds_all = np.concatenate(oof_preds)\n",
    "oof_targets_all = np.concatenate(oof_targets)\n",
    "test_preds_all = np.stack(test_cv_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "physical-condition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF acc: 0.796749\n"
     ]
    }
   ],
   "source": [
    "oof = accuracy_score(oof_targets_all,oof_preds_all)\n",
    "print('OOF acc: %f' % oof)\n",
    "\n",
    "sample_sub = pd.read_csv(\"Sample Submission.csv\")\n",
    "\n",
    "# Lets Take Weighted ensemble\n",
    "base = np.zeros((len(sample_sub)))\n",
    "for itr,prs in enumerate(test_preds_all):\n",
    "    base += (scores[itr]/np.sum(scores))*prs\n",
    "\n",
    "sample_sub['CustomerAttrition'] = 1*(base >= 0.5)\n",
    "\n",
    "sample_sub.replace({1:'Yes', 0:'No'}, inplace=True)\n",
    "sample_sub.to_csv(\"submission_796.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
